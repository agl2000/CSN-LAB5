---
title: "R Notebook"
output: html_notebook
---

```{r}
install.packages("clustAnalytics")
```

```{r}
library("igraph")
library("igraphdata")
library("clustAnalytics") #contains various methods to assess the quality of clusterings
```

## Jaccard similarity

Given two different clusterings of the same network, it outputs a table of the Jaccard index between each of their clusters (i.e. a table that includes the Jaccard index between each cluster of labeling 1 and each cluster of labeling 2).

```{r}
jaccard_sim <- function(GT_clust, clust) {
  # Get unique cluster labels in both lists
  unique_GT <- unique(GT_clust)
  unique_clust <- unique(clust)
  
  # Initialize an empty matrix to store Jaccard similarities
  JS_matrix <- matrix(0, nrow = length(unique_GT), ncol = length(unique_clust))
  
  # Compute the Jaccard similarity for each pair of clusters
  for (i in 1:length(unique_GT)) {
    for (j in 1:length(unique_clust)) {
      # Get the nodes in the i-th GT cluster and j-th predicted cluster
      nodes_GT <- which(GT_clust == unique_GT[i])
      nodes_clust <- which(clust == unique_clust[j])
      
      # Calculate intersection and union of the two sets
      intersection_size <- length(intersect(nodes_GT, nodes_clust))
      union_size <- length(union(nodes_GT, nodes_clust))
      
      # Calculate Jaccard similarity and store it in the matrix
      JS_matrix[i, j] <- intersection_size / union_size
    }
  }
  
  # Set row and column names for the matrix
  rownames(JS_matrix) <- paste(unique_GT)
  colnames(JS_matrix) <- paste(unique_clust)
  
  return(JS_matrix)
}
```

## Match clusters

For each cluster of labeling 1, identifies which is the cluster of labeling 2 that is more similar according to the Jaccard index, and returns all these indices indicating which clusters they correspond to.

```{r}
match_clusters <- function(JS_matrix, name_GT="GT", name_alg="alg") {
  # Initialize an empty list to store the matching pairs
  MC_list <- list()
  
  # Loop over each cluster in the ground truth (GT) (rows of JS_matrix)
  for (i in 1:nrow(JS_matrix)) {
    # Find the index of the cluster in 'alg' with the highest Jaccard similarity for cluster i in 'GT'
    best_match_index <- which.max(JS_matrix[i, ])
    
    # Get the name of the clusters
    GT_cluster_name <- paste(name_GT, rownames(JS_matrix)[i], sep = ".")
    alg_cluster_name <- paste(name_alg, colnames(JS_matrix)[best_match_index], sep = ".")
    
    # Get the Jaccard similarity value
    similarity_value <- JS_matrix[i, best_match_index]
    
    # Create a named entry in the list with the cluster pair and similarity
    MC_list[[paste("(", GT_cluster_name, ",", alg_cluster_name, ")", sep = "")]] <- similarity_value
  }
  
  # Convert the list to a named vector (keys are the cluster pairs, values are the similarity values)
  MC_vector <- unlist(MC_list)
  
  # Convert the vector to a matrix format (one row with the Jaccard similarity values)
  MC_matrix <- matrix(MC_vector, nrow = 1)
  
  # Set the column names to be the cluster pairs
  colnames(MC_matrix) <- names(MC_vector)
  
  # Return the matrix
  return(MC_matrix)
}
```

## Weighted mean

Computes the weighted mean of the vector of values output by previous function (weights given by fraction of number of nodes in each cluster).

This quantity we will consider as the (global) Jaccard similarity of the two clusterings.

```{r}
Wmean <- function(MC_matrix, GT_clust, clust, algorithm_name) {
  # Initialize variables
  total_weighted_similarity <- 0
  total_weight <- 0
  
  # Extract cluster pair names from the column names of the MC_matrix
  cluster_pairs <- colnames(MC_matrix)
  
  # Loop over each cluster pair to calculate weighted similarity
  for (pair in cluster_pairs) {
    # Remove parentheses first
    clean_pair <- gsub("[()]", "", pair)
    
    # Split the pair into GT and algorithm cluster parts
    gt_cluster <- as.numeric(sub("GT\\.", "", strsplit(clean_pair, ",")[[1]][1]))  # Remove "GT." and convert to numeric
    lv_cluster <- as.numeric(sub(paste0(algorithm_name, "\\."), "", strsplit(clean_pair, ",")[[1]][2]))  # Remove dynamic algorithm prefix
    
    # Get the size of the clusters (number of nodes)
    gt_size <- sum(GT_clust == gt_cluster)
    lv_size <- sum(clust == lv_cluster)
    
    # Calculate the weight for the cluster pair (fraction of nodes in both clusters)
    weight <- gt_size / length(GT_clust) + lv_size / length(clust)
    
    # Get the Jaccard similarity value from the matrix
    similarity_value <- MC_matrix[1, pair]
    
    # Update the weighted sum
    total_weighted_similarity <- total_weighted_similarity + (weight * similarity_value)
    total_weight <- total_weight + weight
  }
  
  # Calculate the weighted mean
  w_mean_value <- total_weighted_similarity / total_weight
  
  return(w_mean_value)
}
```

## Alternative to global Jaccard similarity

```{r}

# Can you think of another way of combining the vector of Jaccard indices obtained in match_clusters() to quantify clusterings similarity?

# Harmonic Mean for Global Jaccard Similarity
harmonic_mean <- function(MC_matrix, GT_clust, clust, algorithm_name) {
  # Extract similarities from the match clusters matrix
  similarities <- as.numeric(MC_matrix)
  # Calculate harmonic mean
  harmonic_mean_value <- length(similarities) / sum(1 / similarities)
  return(harmonic_mean_value)
}

```

# Code to plot a graph and its clustering
```{r}
# Plot community structure for a given graph and clustering
plot_communities <- function(graph, clustering, title) {
  plot(graph, vertex.color = clustering, main = title, vertex.label = NA, vertex.size = 10)
}

# Plot dendrogram for hierarchical clustering
plot_dendrogram <- function(graph, algorithm) {
  if (algorithm == "fastgreedy") {
    dendrogram <- cluster_fast_greedy(graph)
    dendPlot(dendrogram)
  } else {
    message("Dendrogram not supported for this algorithm.")
  }
}
```


# Load/generate datasets

```{r}
# Karate
data(karate,package="igraphdata")
plot(karate,main = "Karate Network")

# Synthetic network: scale-free degree distribution, 200 nodes, 800 edges and 4 communities
B <- matrix(c(1, 0.5, 0.3, 0.1,
              0.5, 1, 0.4, 0.8,
              0.3, 0.4, 1, 0.7,
              0.1, 0.8, 0.7, 1), ncol=4)
synthetic_graph <- barabasi_albert_blocks(m=4, p=c(0.25, 0.25, 0.25, 0.25), B=B, t_max=200,
                     type="Hajek", sample_with_replacement = FALSE)
plot(synthetic_graph,main = "Synthetic Network")

# ENRON
data(enron,package="igraphdata")
enron_adj <- as_adjacency_matrix(as.undirected(enron,mode = "each"))
enron_graph <- graph_from_adjacency_matrix(enron_adj, mode = "undirected", diag = FALSE)
plot(enron_graph, main="Enron Network")


#Custom graph (UK faculty)

data("UKfaculty",package="igraphdata")
undirected_graph <- as.undirected(UKfaculty, mode = "collapse")  # Combine directed edges into one undirected edge
plot(undirected_graph,main = "UKfaculty Network",vertex.label=NA)
custom_graph<-undirected_graph

```

## Define functions

```{r}
get_cluster_memberships_from_graph <- function(graph, algorithm) {
  
  # Clustering using Walktrap
  if (algorithm == "walktrap") {
    results <- cluster_walktrap(graph)
  }
  
  # Clustering using Betweenness
  else if (algorithm == "betweenness") {
    results <- cluster_edge_betweenness(graph)
  }
  
  # Clustering using Fast Greedy
  else if (algorithm == "fastgreedy") {
    results <- cluster_fast_greedy(graph)
  }
  
  # Clustering using Label Propagation
  else if (algorithm == "propagation") {
    results <- cluster_label_prop(graph)
  }
  
  # Clustering using Eigenvector
  else if (algorithm == "eigenvector") {
    results <- cluster_eigenvector(graph)
  }
  
  # Clustering using Multilevel
  else if (algorithm == "multilevel") {
    results <- cluster_louvain(graph)
  }
  
  # Clustering using Optimal (Modularity-based)
  else if (algorithm == "optimal") {
    results <- cluster_optimal(graph)
  }
  
  # Clustering using Spinglass
  else if (algorithm == "spinglass") {
    results <- cluster_spinglass(graph)
  }
  
  # Clustering using Infomap
  else if (algorithm == "infomap") {
    results <- cluster_infomap(graph)
  }
  
  # Check if the algorithm provided is valid
  else {
    stop("Invalid algorithm specified. Please choose one of: 'walktrap', 'betweenness', 'fastgreedy', 'propagation', 'eigenvector', 'multilevel', 'optimal', 'spinglass', 'infomap'.")
  }
  cluster_list <- unname(membership(results))
  # Return the clustering result
  return(cluster_list)
}

```



## 1. Define the algorithms we want to use

```{r}
algorithm_functions <- list(
  walktrap = cluster_walktrap, #is asked
 betweenness = cluster_edge_betweenness, #is asked
  #fastgreedy = cluster_fast_greedy,
  propagation = cluster_label_prop, #is asked
  #eigenvector = cluster_eigenvector,
 multilevel = cluster_louvain, #is asked
  #optimal = cluster_optimal,
  #spinglass = cluster_spinglass,
  infomap = cluster_infomap
)
```

## 2. Define the scoring functions we want to use to evaluate the clustering significance (a representative of each class) + Jaccard similarity (local and global)

```{r}
#Internal connectivity (high is best)
int_cnctvty <- c(
  "clustering coef",
  "internal density",
  "edges inside",
  "av degree",
  "FOMD"
)
#External connectivity (low is best)
ext_cnctvty <- c(
  "expansion",
  "cut ratio"
)
#Combine internal and external connectivity (low is best)
int_ext_cnctvty <- c(
  "conductance",
  "norm cut",
  "max ODF",
  "average ODF",
  "flake ODF"
)
#Based on a network model (high is best)
net_model <- c(
  "modularity"
)
```

## 3. Find a good reference clustering for each network

-   Ground truth for Karate and Synthetic graph

-   Best ranked clustering (according to your selected group of scoring functions) for ENRON and the other.

    ```{r}
    find_best_algorithm <- function(matrix, int_cnctvty, ext_cnctvty, int_ext_cnctvty, net_model) {
      # Extract the algorithms dynamically from the column names
      algorithms <- colnames(matrix)
      
      best_scores <- sapply(algorithms, function(alg) {
        
        # Initialize counters for best scores
        best_count <- 0
        
        # Iterate over internal connectivity functions
        for (metric in int_cnctvty) {
          # Check if the current algorithm's score is the highest for this metric
          if (!any(is.na(matrix[metric, ]))) { # Skip if all values are NA
            if (matrix[metric, alg] == max(matrix[metric,])) {
              best_count <- best_count + 1
            }
          }
        }
        
        # Iterate over external connectivity functions
        for (metric in ext_cnctvty) {
          # Check if the current algorithm's score is the lowest for this metric
          if (!any(is.na(matrix[metric, ]))) { # Skip if all values are NA
            if (matrix[metric, alg] == min(matrix[metric,])) {
              best_count <- best_count + 1
            }
          }
        }
        
        # Iterate over combined internal-external connectivity functions
        for (metric in int_ext_cnctvty) {
          # Check if the current algorithm's score is the lowest for this metric
          if (!any(is.na(matrix[metric, ]))) { # Skip if all values are NA
            if (matrix[metric, alg] == min(matrix[metric,])) {
              best_count <- best_count + 1
            }
          }
        }
        
        # Iterate over network model functions (modularity)
        for (metric in net_model) {
          # Check if the current algorithm's score is the highest for this metric
          if (!any(is.na(matrix[metric, ]))) { # Skip if all values are NA
            if (matrix[metric, alg] == max(matrix[metric,])) {
              best_count <- best_count + 1
            }
          }
        }
        
        return(best_count)
      })
      
      # Find the algorithm with the maximum number of best scores
      best_algorithm <- names(best_scores)[which.max(best_scores)]
      print(best_scores)
      return(best_algorithm)
    }
    ```

```{r}
#Find best algorithm to get the clustering GT of ENRON and custom

# Define metrics of interest
all_interested_metrics <- c(int_cnctvty, ext_cnctvty, int_ext_cnctvty, net_model)


# Evaluate significance and determine the best algorithm for ENRON
no_clustering_coef_flag <- !("clustering coef" %in% int_cnctvty)
enron_scores <- evaluate_significance(
  enron_graph,
  alg_list = algorithm_functions,
  no_clustering_coef = no_clustering_coef_flag
)
enron_scores_filtered <- enron_scores[rownames(enron_scores) %in% all_interested_metrics, ]
enron_best_algorithm <- find_best_algorithm(
  enron_scores_filtered, int_cnctvty, ext_cnctvty, int_ext_cnctvty, net_model
)
print(paste("Best algorithm for ENRON:", enron_best_algorithm))



# Evaluate significance and determine the best algorithm for Custom Network
custom_scores <- evaluate_significance(
  custom_graph,
  alg_list = algorithm_functions,
  no_clustering_coef = no_clustering_coef_flag
)
custom_scores_filtered <- custom_scores[rownames(custom_scores) %in% all_interested_metrics, ]
custom_best_algorithm <- find_best_algorithm(
  custom_scores_filtered, int_cnctvty, ext_cnctvty, int_ext_cnctvty, net_model
)
print(paste("Best algorithm for Custom Network:", custom_best_algorithm))

# Extract GT clustering based on the best algorithm
enron_GT <- get_cluster_memberships_from_graph(enron_graph, enron_best_algorithm)
custom_GT <- get_cluster_memberships_from_graph(custom_graph, custom_best_algorithm)

# Print results
print("ENRON GT Clustering:")
plot(enron_GT)

print("Custom Network GT Clustering:")
plot(custom_GT)


```
```{r}
plot_communities(
  custom_graph, 
  custom_GT,  # Use your clustering results
  "Custom Graph with Clustering"
)

plot_communities(
  enron_graph, 
  enron_GT,  # Use your clustering results
  "Enron Graph with Clustering"
)
```




## 4. Evaluate

```{r}

plot_communities(
  custom_graph, 
  custom_GT,  # Use your clustering results
  "Custom Graph with Clustering"
)

visualize_results("net_name",custom_graph, custom_scores)
# Visualize all networks
for (net_name in names(networks)) {
  graph <- networks[[net_name]]$graph
  results <- all_results[[net_name]]
  visualize_results(net_name, graph, results)
}


```


```{r}
# Evaluate networks
evaluate_network <- function(graph, ground_truth = NULL, algorithms = algorithm_functions) {
  results <- list()
  metrics<-evaluate_significance(graph,alg_list = algorithm_functions)
  for (alg_name in names(algorithms)) {
    
    clustering <- get_cluster_memberships_from_graph(graph, alg_name)
    
    if (!is.null(ground_truth)) {
      # Compare with ground truth
      JS_matrix <- jaccard_sim(ground_truth, clustering)
      MC <- match_clusters(JS_matrix, "GT", alg_name)
      weighted_js <- Wmean(MC, ground_truth, clustering, alg_name)
      harmonic_js <- harmonic_mean(MC)
    } else {
      # Compare with best clustering (to be determined)
      weighted_js <- NA
      harmonic_js <- NA
    }
    
    results[[alg_name]] <- list(
      clustering = clustering,
      weighted_js = weighted_js,
      harmonic_js = harmonic_js,
      metrics = metrics
    )
  }
  return(results)
}

# Prepare networks
networks <- list(
  karate = list(graph = karate, ground_truth = V(karate)$Faction),
  synthetic = list(graph = synthetic_graph, ground_truth = V(synthetic_graph)$label),
  enron = list(graph = enron_graph, ground_truth = enron_GT),
  custom = list(graph = custom_graph, ground_truth = custom_GT)
)

# Evaluate all networks
all_results <- lapply(names(networks), function(net_name) {
  network <- networks[[net_name]]
  evaluate_network(network$graph, network$ground_truth)
})

```



```{r}
# Summarize results into a table
summarize_JS <- function(network_name, results) {
  summary <- data.frame(
    Algorithm = names(results),
    Weighted_JS = sapply(results, function(r) r$weighted_js),
    Harmonic_JS = sapply(results, function(r) r$harmonic_js)
  )
  print(paste("Results for", network_name))
  # print(summary)
  return(summary)
}

summarize_metrics <- function(network_name, results) {
  summary <- metrics = results$walktrap$metrics
  
  print(paste("Results for", network_name))
  # print(summary)
  return(summary)
}

  
i=1
for (name in names(networks)){
    print(name)
    print(summarize_JS(name, all_results[[i]]))
    print(all_results[[i]]$walktrap$metrics)
  i=i+1
}

 

```






